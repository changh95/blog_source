---
title: Qin 2018 - VINS-Mono - A Robust and Versatile Monocular Visual-Inertial State Estimator
date: 2021-04-01 00:00:21
mathjax: true
tags: 
- SLAM
- Visual-SLAM
- VINS-Mono
- HKUST
categories: 
- [SLAM, 논문 리뷰]
excerpt: Tong Qin, Peiliang Li, Shaojie Shen의 TRO 2018 논문인 VINS-Mono의 정리입니다.
---

[Arxiv 논문 링크](https://arxiv.org/pdf/1708.03852.pdf)

[Github 링크](https://github.com/HKUST-Aerial-Robotics/VINS-Mono)

## Abstract

- VINS는 **V**isual-**IN**ertial **S**ystem을 줄인 말이다.
  - Monocular camera + IMU를 함께 사용해서 6DOF pose를 구하는 시스템이다.
- Monocular camera는 거리 값을 추정할 수 없다. 이 때문에
  - IMU 센서 값을 정확하게 보정해주거나
  - 정확한 initialization을 하거나
  - 정확한 Extrinsic calibration을 하거나
  - 비선형 최적화가 어렵다 (ㅠㅠ)
- 논문에서 제안하는 VINS-Mono는 다음과 같은 구조로 6DOF pose를 추정한다.
  1. Robust한 initialization을 수행한다.
     - Failure recovery에도 동일한 알고리즘이 사용된다.
  2. Visual-inertial odometry 모듈에서는 tightly-coupled 방식으로 비선형 최적화를 수행한다.
     - Pre-integrated IMU 값과 visual feature 정보를 동시에 최적화하면서 local pose를 구한다.
  3. Loop detection과 tightly-coupled 방식의 최적화를 이용하여 계산량이 적은 relocalization을 수행한다.
  4. Global consistency를 유지하기 위해 4-dof pose graph optimization을 수행한다.
  5. PC 버전과 iOS 모바일 버전을 (VINS-Mobile) 만들었다.

&nbsp;

---
## Introduction

### Monocular state estimation의 특징

- Monocular Camera로 state estimation (i.e. SLAM, visual odometry)을 하는데에는 여러 장점이 있다.
  - 카메라를 하나만 쓰면 전체 시스템이 작고, 가격이 저렴하고, 하드웨어를 구성하기 쉽다.


- 하지만 단점도 있다.
  - Metric scale을 구할 수 없다 (i.e. 계산을 할 때 $\lambda$ scale factor를 구할 수 없다. 즉, 실제 거리 단위를 모른다)

### Visual-inertial odometry (VIO)의 등장

- 최근따라 monocular camera + IMU를 사용하는 시도가 늘고 있다. 장점이 있기 때문이다.
  1. IMU 센서 값은 metric scale을 포함하고 있다.
     - 즉, metric scale을 구할 수 있다.
     - 또, roll + pitch + yaw 값들에 대한 정보도 함께 state estimation에 사용할 수 있게 된다.
  2. 전체적인 motion tracking 성능이 비약적으로 좋아진다.
     - IMU 센서의 값을 얻는 속도가 camera 센서 이미지를 얻는 속도보다 훨씬 빠르기 때문에, camera 프레임들 사이의 우리가 알지 못하는 motion 값을 메워줄 수 있다.
     - 특히, texture가 적은 곳, 조명 변화, motion blur등이 생김으로써 camera 센서 값이 무용지물이 됬을 때 IMU가 그 부분을 채워주면서 tracking을 유지할 수 있다.


- 하지만 monocular camera + IMU 조합도 단점이 있다.
  1. Metric scale을 복원하기 위해서는 IMU는 무조건 움직여야한다.
     - Metric scale은 initialization 단계에서 계산해낸다.
       - Initialization 단계에서 움직임이 (i.e. acceleration) 있어야한다는 뜻이다.
       - 즉, VIO는 무조건 움직이는 / 가속하는 상황에서만 시작할 수 있다.
       - 반대로, 가만히 있는 상태에서는 가속이 없으므로 시작할 수는 없다.
     - 가만히 있는 상태는 보통 우리가 알고 있는 상태이다.
     - 반대로, '움직이는 상황'은 경우의 수가 굉장히 많다. 속도가 다를 수 있고, 방향이 다를 수 있다.
       - 즉, metric scale을 복원하려면 무조건 '잘 모르는 상태에서 가속하는 상황'을 전제로 두게 된다.
       - 이는 문제가 많이 복잡하게 만든다.
  2. Visual-inertial system은 센서들 특성상 굉장히 non-linear 하다.
        - 이러한 특성은 정확한 initialization을 어렵게 한다.
        - 추후 visual-inertial odometry에서도 쉽지 않다. Non-linear optimization은 계산량도 많고 복잡하기 때문이다.
  3. 센서를 2개를 사용하기 때문에 extrinsic calibration이 필요한다.
        - Extrinsic calibration은 굉장히 정확해야한다.
  4. Long-term drift를 해소하기 위해서는 visual-inertial odometry, loop detection, relocalization, global optimization 모듈이 전부 필요하다.
        - 이걸 다 만든 연구는 거의 없다. 아마 이 논문이 나왔을 당시에는 아예 없었을수도?

### VINS-Mono

- 논문에서 소개하는 VINS-Mono 시스템은 다음과 같은 특성을 지닌다.
  1. 프로그램 시작하고 움직이면 알아서 initialization이 된다 (i.e. on-the-fly로 된다!)
     - Failure recovery에도 동일한 알고리즘이 사용된다.
  2. VIO는 tightly-coupled 방식의 비선형 최적화를 사용한다.
     - VIO로부터 Local pose, velocity, orientation을 구할 수 있다.
       - (Pose에 orientation이 들어가있지 않나...? 지자기계의 orientation을 의미하는걸까? 확인이 필요하다) 
     - Camera-IMU extrinsic calibration + IMU bias correction도 실시간으로 수행하면서 보정해나간다.
       - 쩐다!
  3. Loop detection은 DBoW2 라이브러리를 사용한다.
  4. Relocalization은 tightly-coupled 방식으로 feature 단위로 VIO와 fusion한다.
     - "feature 단위로..." 부분은 정확한 내용은 뒤에서 다시 짚는다.
     - 이 방식을 통해 계산량을 현저히 감소시켰다.
  5. 4dof pose grpah optimization을 통해 global consistency를 유지한다.
     - 이는 Loop detection + relocalization을 통해 얻어낸 loop를 pose graph에 추가하고
     - VIO로부터 관측된 roll + pitch 각도 값을 이용해서 pose graph optimization을 수행한다.


- VINS-Mono의 이전 연구는 다음과 같다.
  - [Shen 2015 - Tightly-coupled monocular visual-inertial fusion for autonomous flight of rotorcraft MAV](https://youtu.be/84jZg7hXEVc)
  - [Yang 2017 - Monocular visual-inertial state estimation with online initialization and camera-imu extrinsic calibration](https://ieeexplore.ieee.org/document/7463059)
  - [Qin 2017 - Robust initialization of monocular visual-inertial estimation on aerial robots](https://ieeexplore.ieee.org/document/8206284)
  - [Li 2017 - Monocular visual-inertial state estimation for mobile augmented reality](https://ieeexplore.ieee.org/document/8115400)
- 여기서 VIO는 Shen 2015, Yang 2017 논문들을 참조했고, initialization 모듈은 Qin 2017 논문을 참조했다. 모바일 버전은 Li 2017을 참조했다.
- 이전 논문과 다른 점이라면,
  - IMU pre-integration을 사용한 bias correction 구현과
  - tightly-coupled relocalization 모듈 구현,
  - global pose optimization 모듈 구현,
  - 그리고 많은 양의 실험 + 코드의 오픈소스화 이다.

&nbsp;

---
## Related Work

### Vision 기반 state estimation / odometry / SLAM

- 비전 기반 state estimation / odometry / SLAM에는 다음과 같은 논문이 있다.
  - PTAM
  - SVO
  - LSD-SLAM
  - DSO
  - ORB-SLAM

### 좀 옛날의 filter 기반 방식들

- Visual과 inertial 정보를 섞는 가장 쉬운 방식은 Loosely-coupled 방식이다.
  - Weiss 2012, Lynen 2013 논문
  - Visual과 inertial의 정보를 각각 따로 얻고 그냥 짬뽕하는 것이다.


- EKF를 사용해서 Visual + inertial fusion을 할 수 있다.
  - IMU는 state propagation을 하고, Vision으로는 pose 업데이트를 한다.
  - 그 다음 두개의 probability distribution을 짬뽕하는 것

### 유명한 filter 기반 방식들?

- [Mourikis 2007 - MSCKF](https://ieeexplore.ieee.org/document/4209642)는 잘된다!
  - EKF 방식
  - 이전 몇개의 camera pose를 state vector에 담아두고, 여러 카메라 뷰에서 공톡적으로 보이는 keypoint들을 기반으로 추정함.
    - i.e. multi-constraint update


- SR-ISWF 는 MSCKF의 개량된 버전임
  - Square-root form을 사용해서 계산 안정성을 높힘
  - Inverse filter를 사용해서 iterative re-linearization을 수행하는데, 이러한 과정이 optimization기반 odometry 방식과 유사해짐.

### Optimization 방식들

- Optimization 방식은 주로 batch graph optimization 또는 bundle adjustment 방식을 뜻하는 것임.
  - 가능한 모든 measurement들을 최적화해서 optimal state (i.e. optimal camera pose, optimal map point)를 구하는 것이 목적


- 매 프레임 비슷한 양의 계산 시간을 가져가기 위해 VIO에서는 sliding window optimization 기법을 사용함.
  - Sliding window optimization은 최근 몇개의 프레임들만 사용하는 것임.
  - 그 이전의 프레임들은 모두 marginalize 해버림 (i.e. 가장 오래된 프레임 값에 하나의 measurement로 묶어버림).
  - 이 방식을 통해 모든 measurement를 사용하는 것 보다 훨씬 빠르게 계산을 할 수 있음.
    - 그럼에도 계산량이 많은 편이라 보통 모바일 기기에서 돌아가는 알고리즘은 얼마 없음 (...라고 말하지만 결국 '그럼에도 불구하고' VINS-Mobile은 모바일에서 돌아간다고 자랑하려고 적은거인듯!)
      - (실제로 돌아가는게 많이 있진 않음 ㅋㅋ 맞는말이지만 자랑하는게 너무 티나서...)

### Direct vs Indirect 방식

- Optimization 방식은 residual 값을 최소화하며 optimal state를 구하는 방향으로 최적화를 수행하는 것임.


- Residual을 계산하는데에는 direct 방식과 indirect (i.e. feature-based) 방식이 있음.
  - Direct 방식은 photometric error를 최소화함
  - Indirect 방식은 reprojection error를 최소화함 (논문에서는 geometric displacement라고 표현)


- Direct 방식은 좋은 initial guess가 필요한 반면에, indirect 방식은 keypoint를 추출하고 매칭하는데에 리소스를 할애해야함.


- 대부분의 SLAM 논문들에는 Indirect 방식이 인기가 많지만, dense mapping을 위해 direct 방식을 채택하기도 함.

### IMU

- IMU는 camera보다 훨씬 빠른 속도로 센서 값을 취득함. (200Hz vs 30Hz)
- IMU를 사용하는 방식은 다양함
  - EKF - IMU를 state propagation에 이용함
  - Graph optimization - IMU pre-integration 방식을 많이 사용함.
- IMU preintegration?
  - 반복되는 IMU re-integration을 피하기 위해 사용됨.
  - Lupton 2012 논문에서 최초 제안. Euler angle을 사용해서 rotation error를 parameterize함.
  - VINS-Mono 논문의 저자도 IMU-preintegration을 위한 on-manifold rotation formulation연구 수행.
    - IMU eeror state dynamics를 continuous time으로 보았을 때 covariance propagation하여 수행.
    - 대신 IMU bias는 고려하지 않았음
      - (사실상 저가형 IMU에서는 이게 제일 중요한데...)
  - [Forster 2015 - On-Manifold Preintegration for Real-Time Visual-Inertial Odometry](https://arxiv.org/abs/1512.02363)
    - 랜드마크 논문. 킹킹킹 논문! Posterior IMU bias correction을 넣어서 아이디어를 완성한 논문!

### VINS bootstrapping

- VINS initialization을 이 논문에서는 VINS bootstrap 이라고 함.
  - Monocular VINS bootstrap을 위해서는 정확한 initial 값이 있어야함.
  - 예전에 제안된 방법으로는 linear한 방식으로 initialize하는 방법이 있었음.
    - 짧은 시간동안의 IMU preintegration값들로부터 상대적인 회전 값을 이용한다 어쩌구 하는데
    - 별로 안좋다고 함.
      - gyroscope bias도 모델링을 못하고
      - Projection equation에도 센서 노이즈를 전혀 모델링하지 못한다고...
    - 즉, 못씀!
  - Martinelli 2014 논문과 Kaiser 2016 논문에서 closed-form으로 initialization하는 방법을 발표함. 2016년 논문은 2014년 논문에 gyroscope bias도 계산하는 것을 추가한 것.
    - 이 방법들은 오랜 시간동안 IMU 값들을 2번 적분해서 거리값을 구해서 쓰기 때문에, 노이즈에 취약하지만 이 노이즈를 전혀 모델링하지 않음.
      - 즉, 못씀!
    - (Scaramuzza 교수님은 이 논문들 좋다고 하셨는데... ㄷㄷ)
  - SVO 기반으로 re-initialization + failure recovery를 하는 알고리즘도 있음
    - 하지만 SVO 알고리즘 특성상 바닥을 바라보는 드론 카메라를 기반으로 만들어졌고, 드론의 높이 값을 알고 있을 때를 상정하고 있음.
    - 그리고 이 높이 값을 알아야 metric scale을 구할 수 있음.
      - 즉, 못씀!
  - ORB-SLAM 기반으로 visual-inertial full bundle-adjustment를 통해서 scale, gravity direction velocity, IMU bias를 전부 얻어내는 방법도 있음.
    - 근데 좋은 값으로 수렴하는데에 10초나 걸림
    - 너무 오래걸림. 못씀!


- 결국은 저자들이 지난 논문에서 제안했던 방법을 씀.

### Loop closure

- VIO도 오랜 시간 실행하면 drift가 쌓임.
- ORB-SLAM은 Bag-of-Words (i.e. DBoW2 라이브러리)를 이용해서 loop closure도 하고 map reuse도 가능함.
  - Loop detection이 일어나면 7 DOF (position - xyz, orientation - rx|ry|rz, scale $\lambda$) pose graph optimzation을 수행하는 방식임.
- VINS는 IMU가 있기 때문에 drift는 4DOF (position - xyz, orientation - yaw) 로만 일어남.
  - 그러므로 이번 논문에서는 최소 4DOF 셋팅으로 pose graph optimization을 할 예정임.

&nbsp;

---

## Overview

- 프로그램이 시작하면 visual keypoint를 추출하고 트랙킹을 수행한다. IMU는 2개의 프레임 간의 값을 preintegrate한다.
- Initialization을 수행해서 pose, velocity, gravity vector, gyroscope bias, 3D feature location을 구한다.
  - 이 값들은 비선형 최적화 기반의 VIO를 시작하는데에 (i.e. bootstrapping)하는데에 쓰인다.
- VIO, relocalization, pose graph optimization이 멀티쓰레딩으로 동시에 돌아간다.
  - VIO와 relocalization모듈은 preintegrate된 IMU 값들과 visual keypoint 값들, 그리고 loop detection이 되었을 때 찾은 공통된 visual keypoint들을 가지고 tightly-fuse (i.e. 비선형 최적화)를 한다.
  - Relocalization이 성공하면, 이 값들을 가지고 pose graph optimization 모듈이 global optimization을 수행해서 drift를 제거한다.


- 앞으로 논문에서 사용할 notation들을 설명한다.
  - $(\cdot)^\omega$은 world frame이며, z 방향이 중력의 방향이다.
  - $(\cdot)^b$는 body frame (i.e. IMU frame)
  - $(\cdot)^c$는 카메라 프레임이다.
  - $R$은 3x3 rotation matrix
  - $q$는 쿼터니언
    - State vector는 쿼터니언을 쓰지만, 종종 특정 부분에서 계산을 쉽게 하기위해 $R$을 쓰기도 할 것이다.
    - $\otimes$는 쿼터니언 곱셈이다.
  - $q_{b}^{\omega}$ 와 $p_{b}^{\omega}$는 rotation과 translation을 body frame -> world frame으로 표현한 것이다.
  - $b_{k}$는 k번째 body frame이다.
  - $c_{k}$는 k번째 camera frame이다.
  - $g^\omega = [0,0,g]^T$는 world frame으로 표현한 gravity vector이다.
  - $\hat{(\cdot)}$은 두가지 의미를 지닌다.
    - 노이즈가 낀 값이거나
    - 어떠한 추정 값이다.

&nbsp;

---

## Measurement preprocessing

