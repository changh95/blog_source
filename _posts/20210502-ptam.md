---
title: Klein & Murray 2007 - Parallel Tracking and Mapping for Small AR Workspaces (PTAM)
date: 2021-05-02 14:34:42
mathjax: true
tags: 
- PTAM
- SLAM
- Visual-SLAM
categories: 
- [SLAM, 논문 리뷰]
excerpt: Klein & Murray 2007 PTAM 논문 리뷰
---

## Abstract

- Hand-held 카메라로 small AR workspace에서 잘 작동하는 SLAM을 만들었다.
- 실시간 조건으로 작동하게 하기 위해 **tracking** 작업과 **mapping** 작업을 **여러 CPU thread에 병렬처리**하였다 (i.e. "Parallel" tracking and mapping...).
  - Tracking - 빠른 hand-held motion을 추정하는 모듈
  - Mapping - 지난 프레임들에서 추출된 keypoints들을 기반으로 3D map을 생성하는 모듈.
- 이러한 병렬처리 구조를 통해 계산량이 많은 **bundle adjustment** 기법을 실시간에 작동하도록 구현할 수 있었다.

&nbsp;

## Introduction

- 보통 증강현실 프로그램과 같이 어떠한 환경에서 카메라의 위치를 추정하는데에는 '**사전에 미리 측량해둔 주변 환경**'에 대한 정보가 (i.e. **geometric prior**) 필요하다.
  - [Fiducial marker](https://april.eecs.umich.edu/software/apriltag)를 사용하거나, 또는 이런 마커들을 사전에 정의해둔 위치에 부착해둔다던지
  - [CAD-model](https://www.researchgate.net/publication/26483368_Tracking_of_industrial_objects_by_using_CAD_models)로 만들어둔 환경이라던지
  - 지도를 미리 따둔다던지... ([SfM](https://en.wikipedia.org/wiki/Structure_from_motion)?)
  - 이렇게 '사전에 가지고 있는 정보' + '현재 카메라 프레임에서 보이는 정보'를 **정합** (i.e. registration)함으로써 현재 위치를 파악할 수 있다.

{% asset_img "geometric_priors.png" "geometric_priors" %}

&nbsp;

- 하지만 2007년 이 당시에는 큰 공간의 맵을 만드는 것은 어려웠다.
  - 공간의 map을 정확하게 딴다는 것, 그리고 그것을 이용해서 위치를 추정한다는 개념은 굉장히 복잡한 개념이였다.
  - 2D LiDAR에 대해서는 연구가 어느정도 되었지만 Visual-SLAM쪽은 거의 없었다.
    - (어떻게보면 PTAM이 잘되는 Visual-SLAM의 시작이였으니...)
- 대부분의 '**사전 정보**'는 하나의 fiducial marker, 또는 하나의 object에 대한 정보만 가졌다.
  - 카메라가 이 marker나 object를 바라보다가 시야를 다른 곳으로 돌릴 경우, 더 이상 정합을 할 수 없어 위치 추정이 끊기게 되었다.
  - 이러한 문제를 풀기 위해 '**Extensive tracking**' 기술에 대한 연구가 진행되었다 (AR업계에서는 Extended tracking이라고도 부른다).
    - Marker나 object의 정보를 '최초 환경 정보'로 사용하며, 이 '최초 환경 정보'에 점차 '주변 환경에 대한 정보'를 이어붙여나가는 것이다.
      - 이런 방식을 통해 최초 시야를 벗어나게 되어도 지속적으로 '주변 환경' 정보를 계속 관찰하며 카메라가 자신의 위치를 추정할 수 있는 것이다.

{% asset_img "extended_tracking.png" "extended_tracker" %}

&nbsp;

- 하지만 역시 **최종 형태**는 이러한 **'사전 정보를 전혀 가지지 않은 상태'에서 map을 만들어나가는 것**일 것이다 (**== SLAM!**).
  - **이 논문은 이러한 방식에 초점을 맞춘다** (딴 얘기에 대한 서론이 엄청 길다 ㅋㅋ...)
- 실시간으로 prior map 없이 카메라 위치 트랙킹 + 주변 환경 맵핑을 할 수 있으면 무엇이 좋은가?
  - VR을 위한 remote expert 시스템을 만들 수 있다... 블라블라...
- 이러한 시스템을 만들기 위한 제약이 무엇인가?
  - **주변 환경은 고정되어야한다** (i.e. **static**). 즉, 형태가 바뀌면 안되고, 움직이는게 없어야한다.
  - **주변 환경이 작아야한다**
    - (이는 PTAM이 만든 제약이다. PTAM 이후의 연구들은 large-scale SLAM으로 연구 방향을 바꾼다)

&nbsp;

---

## Method overview in the context of SLAM

- **PTAM의 특징**:
  - Tracking과 Mapping 작업의 분리. (여러 CPU thread에 나눠놓음)
  - Mapping은 keyframe의 정보만 이용해서 수행. (i.e. Bundle adjustment 기법 사용)
  - Initialisation은 [Nister 5-point algorithm](https://ieeexplore.ieee.org/document/1211470?denied=)을 사용해서 만듬.
  - 새로운 map point들은 epipolar search를 이용해서 만듬.
  - Map point가 많다! (~몇천개)

아래는 PTAM 이전의 연구들을 정리한 것.

- Hand-held monocular SLAM으로 잘 알려진 알고리즘들은 Andrew Davison의 [MonoSLAM](https://www.doc.ic.ac.uk/~ajd/Publications/davison_etal_pami2007.pdf)과 Eade & Drummond의 [Scalable monocular SLAM](https://ieeexplore.ieee.org/abstract/document/1640794)이 있다.
  - 위 두 방법은 [EKF-SLAM](https://journals.sagepub.com/doi/abs/10.1177/027836498600500404)과 [FastSLAM 2.0](http://robots.stanford.edu/papers/Montemerlo03a.pdf)에서 사용된 **incremental SLAM 파이프라인**을 가져온 것이다.
  - Incremental SLAM 방식은 **tracking과 mapping을 하나의 filter에 넣어서 동시에 추정하는 방식**이다.
    - (사실 Incremental 방식과 Filter 방식이 완벽하게 동일하진 않다. Filter는 Online SLAM을 부르는 방법 중 하나인데, 이 당시의 filter 방식은 모두 incremental하게 진행되었기 때문에 incremental == filter가 성립한다.)
    - 아래 사진과 같이 incremental 방식은 최적화 수식을 '**가장 최근의 state**'를 구하는데에 집중한 방식이다. Incremental 방식의 반대는 'Full SLAM', 즉 이번 논문이 사용한 bundle-adjustment이 되겠다.

{% asset_img "incremental.png" "incremental" %}

&nbsp;

- **저자들은 Hand-held의 경우에는 이러한 incremental SLAM방식이 적합하지 않다**고 한다.
  - EKF-SLAM과 FatSLAM은 로봇을 위해 만들어진 알고리즘이다.
    - 로봇은 보통 주행 중 꽤 좋은 퀄리티의 odometry 값을 받을 수 있고, 꽤 천천히 움직이는 편이다.
  - **Hand-held는 언제든지 움직이는 속도가 바뀔 수 있기 때문에**, 로봇 주행에 비해 **data association 문제가 나타날 확률이 굉장히 높다**.
    - 갑자기 카메라의 이동이 빨라지면서 data association이 한번만 잘못되도 전체적인 map이 꼬인다는 것이다.
- 그렇기 때문에 **Hand-held camera tracking에는 안정적인 data association이 필수다**.
  - 이를 위한 연구가 다음과 같이 진행되었다
    - Covariance-driven gating (i.e. active search)
    - Joint Compatibility Branch and Bound (JCBB)
    - Random Sample Consensus (RANSAC)
  - 그럼에도 **저자들이 원하는 수준으로 잘 되는 방법론은 없었다**.

&nbsp;

- **저자들은 tracking과 mapping 과정을 분리함으로써 이 문제를 해결**하였다.
  - 분리하는 방법은 **2007년 당시 제안되었던 멀티코어 프로그래밍을 이용해서 동시에 연산하는 방법**을 사용하였다.
    - 듀얼코어 ㄷㄷ... 2021년에는 64코어 128코어도 쓰는데...
  - **Tracking은 더이상 mapping 과정에서 생기는 확률적인 불안정함의 영향을 받지 않게 되었다.**
    - 또, tracking 방식도 mapping에 구애받지 않는 다른 방식들을 사용할 수 있게 되었다. 이 논문에서는 coarse-to-fine 방식에 robust estimator를 사용하는 방식을 사용하였다.
  - **Mapping 과정도** 역시 tracking으로 부터 벗어남으로써, **매 프레임마다 mapping 연산을 수행하지 않아도 되게 되었다**.
    - Incremental SLAM은 매 프레임 굉장히 비슷한 이미지들을 처리하면서 컴퓨팅 자원을 낭비한다.
    - **매 프레임마다 연산을 하지 않으면, 정말로 중요한 정보를 가지고 있는 프레임들에 (i.e. Keyframes) 자원소모를 집중해서 연산**할 수 있다.
    - 덕분에 연산량은 많지만 좋은 결과를 내주는 '**Bundle adjustment**' 기법을 적용할 수 있었다.

&nbsp;

- '**Bundle adjustment**' 기법은 Structure-from-Motion (SfM) 연구에서 많이 사용되는 기법이다.
  - Bundle adjustment는 **카메라에서 뽑은 feature point들의 위치를 기반으로 정확한 3D map point와 카메라의 3d pose를 구해내는 방법**이다.
  - 2007년 당시에 개발되었던 방식인 5-point algorithm + 최근 N개의 카메라 포즈들에 bundle adjustment를 적용하는 방법 (i.e. **Local bundle adjustment**)으로부터 영감을 받았다.
  - 저자들은 단순히 local BA만 하는 것이 아닌, global BA도 고려하였다.
    - 기존의 방식들은 단순히 새 프레임을 쌓아가면서 최근 N개의 이미지들만 사용하였다.
    - 하지만 이 역시 시간이 지나면서 에러가 누적될것이다.
    - PTAM의 저자들은 종종 '**저장된 모든 키프레임들에 대해 bundle adjustment**' (i.e. **Global bundle adjustment**)를 수행함으로써 맵의 퀄리티가 오랜 시간이 지나도 유지되도록 하였다.
      - (하지만 이것도 한계가 있으며, 방 한바퀴를 세네바퀴 돌면 에러가 많이 누적된다. 그렇기에 이 논문이 '... for Small AR workspace'인 것이다.)

&nbsp;

---

## Further related work

> 굳이 중요한 부분은 아니지만 Survey 느낌으로 넣은듯.

- 여러가지 monocular SLAM의 성능을 개선시키려는 시도가 있었다.
  - Extended Kalman filter 대신에 particle filter를 사용해서 빠른 모션에 대응하려는 시도.
  - Feature tracking을 할 때 patch에 대한 correlation-based search 대신에 image descriptor를 사용함으로써 더 정확한 트랙킹을 하는 방법
    - (이런 방법이 있음에도... PTAM은 이 방법을 안쓴다 왜지!)
- 나머지 부분들은 Extensive tracking, CAD tracking, initialization 기술 관련 이야기를 하는데... 별로 중요하지 않음.

&nbsp;

---

## The Map

